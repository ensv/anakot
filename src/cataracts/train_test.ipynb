{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font size=\"6\">Cataract Classification</font></h1>\n",
    "\n",
    "In this notebook, uses two retina datasets to challenge the cataract classification.\n",
    "\n",
    "## Contents\n",
    "* [Import libraries](#import)\n",
    "* [Set configurations and read metadata](#set)\n",
    "* [Process Cataract dataset](#process1)\n",
    "* [Process Ocular disease recognition dataset](#process2)\n",
    "* [Create datasets](#create)\n",
    "* [Build the model(1)](#build1)\n",
    "* [Build the model(2)](#build2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries <a name=\"import\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os, glob, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configurations and read metadata <a name=\"set\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 192\n",
    "IMG_WIDTH = 256\n",
    "\n",
    "# cataract dataset\n",
    "IMG_ROOT = '../input/cataractdataset/dataset/'\n",
    "IMG_DIR = [IMG_ROOT+'1_normal', \n",
    "           IMG_ROOT+'2_cataract', \n",
    "           IMG_ROOT+'2_glaucoma', \n",
    "           IMG_ROOT+'3_retina_disease']\n",
    "\n",
    "# ocular-disease-recognition dataset\n",
    "OCU_IMG_ROOT = '../input/ocular-disease-recognition-odir5k/ODIR-5K/Training Images/'\n",
    "ocu_df = pd.read_excel('../input/ocular-disease-recognition-odir5k/ODIR-5K/data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Cataract dataset <a name=\"process1\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.DataFrame(0, \n",
    "                  columns=['paths', \n",
    "                           'cataract'],\n",
    "                  index=range(601))\n",
    "\n",
    "filepaths = glob.glob(IMG_ROOT + '*/*')\n",
    "\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    filepath = os.path.split(filepath)\n",
    "    cat_df.iloc[i, 0] = filepath[0] + '/' + filepath[1]\n",
    "    \n",
    "    if filepath[0] == IMG_DIR[0]:    # normal\n",
    "        cat_df.iloc[i, 1] = 0\n",
    "    elif filepath[0] == IMG_DIR[1]:  # cataract\n",
    "        cat_df.iloc[i, 1] = 1\n",
    "    elif filepath[0] == IMG_DIR[2]:  # glaucoma\n",
    "        cat_df.iloc[i, 1] = 2\n",
    "    elif filepath[0] == IMG_DIR[3]:  # retine_disease\n",
    "        cat_df.iloc[i, 1] = 3\n",
    "        \n",
    "# only sample normal and cataract        \n",
    "cat_df = cat_df.query('0 <= cataract < 2')\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of normal and cataract images')\n",
    "print(cat_df['cataract'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Ocular disease recognition dataset <a name=\"process2\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cataract_mentioned(text):\n",
    "    if 'cataract' in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "ocu_df['left_eye_cataract'] = ocu_df['Left-Diagnostic Keywords']\\\n",
    "                                 .apply(lambda x: has_cataract_mentioned(x))\n",
    "ocu_df['right_eye_cataract'] = ocu_df['Right-Diagnostic Keywords']\\\n",
    "                                 .apply(lambda x: has_cataract_mentioned(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_df = ocu_df.loc[:, ['Left-Fundus', 'left_eye_cataract']]\\\n",
    "        .rename(columns={'left_eye_cataract':'cataract'})\n",
    "le_df['paths'] = OCU_IMG_ROOT + le_df['Left-Fundus']\n",
    "le_df = le_df.drop('Left-Fundus', axis=1)\n",
    "\n",
    "\n",
    "re_df = ocu_df.loc[:, ['Right-Fundus', 'right_eye_cataract']]\\\n",
    "        .rename(columns={'right_eye_cataract':'cataract'})\n",
    "re_df['paths'] = OCU_IMG_ROOT + re_df['Right-Fundus']\n",
    "re_df = re_df.drop('Right-Fundus', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of left eye images')\n",
    "print(le_df['cataract'].value_counts())\n",
    "print('\\nNumber of right eye images')\n",
    "print(re_df['cataract'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large bias in the dataset. So make it even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    df = pd.concat([\n",
    "        df.query('cataract==1'),\n",
    "        df.query('cataract==0').sample(sum(df['cataract']), \n",
    "                                       random_state=SEED)\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "\n",
    "le_df = downsample(le_df)\n",
    "re_df = downsample(re_df)\n",
    "\n",
    "print('Number of left eye images')\n",
    "print(le_df['cataract'].value_counts())\n",
    "print('\\nNumber of right eye images')\n",
    "print(re_df['cataract'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocu_df = pd.concat([le_df, re_df])\n",
    "ocu_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets <a name=\"create\"> </a>\n",
    "Combine the two metadata and use them to load the image data and create datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cat_df, ocu_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, \n",
    "                                     test_size=0.2, \n",
    "                                     random_state=SEED, \n",
    "                                     stratify=df['cataract'])\n",
    "\n",
    "train_df, val_df = train_test_split(train_df,\n",
    "                                    test_size=0.15,\n",
    "                                    random_state=SEED,\n",
    "                                    stratify=train_df['cataract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(df, img_width, img_height):\n",
    "    imgs = []\n",
    "    for path in tqdm(df['paths']):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        imgs.append(img)\n",
    "        \n",
    "    imgs = np.array(imgs, dtype='float32')\n",
    "    df = pd.get_dummies(df['cataract'])\n",
    "    return imgs, df\n",
    "\n",
    "\n",
    "train_imgs, train_df = create_datasets(train_df, IMG_WIDTH, IMG_HEIGHT)\n",
    "val_imgs, val_df = create_datasets(val_df, IMG_WIDTH, IMG_HEIGHT)\n",
    "test_imgs, test_df = create_datasets(test_df, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "train_imgs = train_imgs / 255.0\n",
    "val_imgs = val_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 25 sheets of image data for training\n",
    "\n",
    "f, ax = plt.subplots(5, 5, figsize=(15,15))\n",
    "norm_list = list(train_df[0][:25])\n",
    "for i, img in enumerate(train_imgs[:25]):\n",
    "    ax[i//5, i%5].imshow(img)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    if norm_list[i] == 1:\n",
    "        ax[i//5, i%5].set_title('TrainData: Normal')\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title('TrainData: Cataract')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 25 sheets of image data for Test\n",
    "f, ax = plt.subplots(5, 5, figsize=(15,15))\n",
    "norm_list = list(test_df[0][:25])\n",
    "for i, img in enumerate(test_imgs[:25]):\n",
    "    ax[i//5, i%5].imshow(img)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    if norm_list[i] == 1:\n",
    "        ax[i//5, i%5].set_title('TestData: Normal')\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title('TestData: Cataract')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model(1) <a name=\"build1\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Mish, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "def mish(x):\n",
    "    return tf.keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)\n",
    " \n",
    "get_custom_objects().update({'mish': Activation(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', \n",
    "                 input_shape=input_shape, activation='mish'))\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\n",
    "model.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use some image data augmentation to generate randomly augmented image data from the ImageDataGenerator Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(horizontal_flip=True, \n",
    "                               height_shift_range=0.1,\n",
    "                               fill_mode='reflect') \n",
    "\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n",
    "                                               verbose=1, \n",
    "                                               restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(generator.flow(train_imgs, \n",
    "                                   train_df,\n",
    "                                   batch_size=BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=len(train_imgs)/BATCH_SIZE,\n",
    "                    callbacks=[es_callback, reduce_lr],\n",
    "                    validation_data=(val_imgs, val_df))\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_imgs, test_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model(2) <a name=\"build2\"> </a>\n",
    "We will train using a model that has been pre-trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_height, img_width, n):\n",
    "    inp = Input(shape=(img_height,img_width,n))\n",
    "    efnet = efn.EfficientNetB0(\n",
    "        input_shape=(img_height,img_width,n), \n",
    "        weights='imagenet', \n",
    "        include_top=False\n",
    "    )\n",
    "    x = efnet(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.000003)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(horizontal_flip=True, \n",
    "                               height_shift_range=0.1,\n",
    "                               fill_mode='reflect') \n",
    "\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n",
    "                                               verbose=1, \n",
    "                                               restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(generator.flow(train_imgs, \n",
    "                                   train_df,\n",
    "                                   batch_size=BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=len(train_imgs)/BATCH_SIZE,\n",
    "                    callbacks=[es_callback, reduce_lr],\n",
    "                    validation_data=(val_imgs, val_df))\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_imgs, test_df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
